{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random id- numbers\n",
    "import random\n",
    "\n",
    "vk_users_n=710000000\n",
    "random.seed(7)\n",
    "id_list_raw=[random.randrange(1, vk_users_n+1, 1) for i in range(200000)]  # generate 200000 rnd ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Limits on wall.get calls - 5000 calls per day ======\n",
    "id_chunk=id_list_raw[0:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authorization in VK\n",
    "\n",
    "import vk\n",
    "import json\n",
    "import requests\n",
    "\n",
    "access_token=#your token\n",
    "v='5.154'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "# Hashing ids\n",
    "\n",
    "def hash_user_id(user_id):\n",
    "    return hashlib.sha256(f\"user_{user_id}\".encode()).hexdigest()\n",
    "\n",
    "def hash_post_id(post_id):\n",
    "    return hashlib.sha256(f\"post_{post_id}\".encode()).hexdigest()\n",
    "\n",
    "def parse_results(id_, post, post_df):\n",
    "    post_list=[]\n",
    "    post_list.append(hash_user_id(id_))  # hashed user ID\n",
    "    post_list.append(hash_post_id(post.get('id', -9999)))  # hashed post ID\n",
    "    full_date=datetime.fromtimestamp(post['date'])\n",
    "    post_list.append(datetime.date(full_date))\n",
    "    text_=post['text'].replace(\"\\n\",\" \")\n",
    "    text=text_.replace(\"|\",\" \")\n",
    "    post_list.append(text)\n",
    "\n",
    "\n",
    "    get_record=False \n",
    "    if 'attachments' in post:\n",
    "        for att in post['attachments']:    \n",
    "            if (att['type']=='link'):\n",
    "                post_list.append(att.get('link', {'title':'',}).get('title', ''))\n",
    "                post_list.append(att.get('link', {'description':'',}).get('description', ''))\n",
    "                get_record=True\n",
    "    if not get_record:\n",
    "        post_list.append(\"\")\n",
    "        post_list.append(\"\")\n",
    "\n",
    "\n",
    "    # If it is a repost with a comment, there will be several elements in the history, with several texts. We only take the user's text (the first one).\n",
    "    if 'copy_history' in post:\n",
    "        for att in post['copy_history']:\n",
    "            if att.get('text', '')!=u\"Запись удалена\":\n",
    "                post_list.append(att.get('text', '').replace(\"\\n\",\" \"))\n",
    "                break\n",
    "    else:\n",
    "        post_list.append('')\n",
    "\n",
    "\n",
    "    #==== Check that all list items are not empty (except hash_user_id, date). They may be empty, for example, if only a photo has been added\n",
    "    k=0\n",
    "    for i in range(3, len(post_list)-3):\n",
    "        if len(str(post_list[i]))>0:\n",
    "            k=k+1\n",
    "\n",
    "    if k>0:\n",
    "    #======Only if there is text/ repost of a post or story, we collect information about views/likes/reposts/ =================\n",
    "        post_list.append(post.get('views', {'count':'',}).get('count', ''))\n",
    "        post_list.append(post.get('likes', {'count':'',}).get('count', ''))\n",
    "        post_list.append(post.get('comments', {'count':'',}).get('count', ''))\n",
    "        post_list.append(post.get('reposts', {'count':'',}).get('count', ''))\n",
    "\n",
    "\n",
    "        post_df = pd.concat([post_df, pd.DataFrame(pd.Series(post_list, index=post_df.columns)).T], axis=0, ignore_index=True)\n",
    "        pbar_concat.set_description(\"Last added for  %s\" % id_)\n",
    "        pbar_concat.update()\n",
    "    return post_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main \n",
    "\n",
    "start_i=0\n",
    "\n",
    "day_limit=5000\n",
    "res_folder=#/type you dir for results/\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "format = '%Y-%m-%d'\n",
    "\n",
    "post_df=pd.DataFrame(columns=['user_idh', 'post_idh', 'date', 'text', 'link_title', 'link_description', 'repost_text', 'views', 'likes', 'comments', 'reposts'])\n",
    "err=''\n",
    "\n",
    "# progress bar tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "pbar = tqdm(id_chunk)\n",
    "pbar.set_description(\"Processing id_s\")\n",
    "\n",
    "pbar_concat = tqdm()\n",
    "pbar_concat.set_description(\"Last added for None\")\n",
    "\n",
    "requests_tick = datetime.now()\n",
    "td_hold = (1.05/3)\n",
    "\n",
    "for i, id_ in enumerate(pbar):\n",
    "    \n",
    "    if err=='limit':\n",
    "        break\n",
    "    \n",
    "    offset=0\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        td = (datetime.now() - requests_tick).total_seconds()\n",
    "        if td < td_hold:\n",
    "            time.sleep(td_hold - td)\n",
    "        \n",
    "        requests_tick = datetime.now()        \n",
    "        try:\n",
    "            q = requests.get('https://api.vk.com/method/wall.get', params={\n",
    "                        'access_token':access_token,  \n",
    "                        'v':v,\n",
    "                        'owner_id':id_,\n",
    "                        'count':100,\n",
    "                        'offset':offset,\n",
    "                        'filter':'owner'\n",
    "                        }).json()['response']\n",
    "        except Exception as error:\n",
    "            try:\n",
    "                if q['error']['error_code']==29:\n",
    "                    err='limit'\n",
    "                    print ('Rate limit reached')\n",
    "                    print (i)\n",
    "                    break\n",
    "            except:\n",
    "                break\n",
    "        \n",
    "        if len(q['items']) == 0:\n",
    "            break       \n",
    "        offset=offset+100\n",
    "        \n",
    "        \n",
    "        for post in q['items']:\n",
    "             \n",
    "            full_date_=datetime.fromtimestamp(post['date'])\n",
    "            full_date = full_date_.strftime(format)\n",
    "            post_df=parse_results(id_, post, post_df)\n",
    "\n",
    "name_end=start_i+id_chunk.index(id_)+1\n",
    "name='part_'+str(start_i)+'-'+str(name_end)+'.csv'\n",
    "post_df.to_csv(res_folder+name, sep='|', encoding='utf-8')   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
